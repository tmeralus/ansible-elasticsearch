---
- name: Install kibana rpms
  yum:
    name: [kibana, unzip]
  become: true

- name: Copy kibana yum repo file
  copy:
    src=kibana.repo
    dest=/etc/yum.repos.d/kibana.repo
    mode=0644
  become: true

- name: Copy templated kibana.yml
  template:
    src=kibana.yml.j2
    dest=/etc/kibana/kibana.yml
    mode=0644
  become: true

- name: Populate elasticsearch index with local logs via rsyslog
  command: systemctl restart rsyslog.service
  ignore_errors: true
  become: true

- name: Setup kibana service
  service: name=kibana.service state=started enabled=true
  become: true

- name: Restart kibana server
  command: systemctl restart kibana.service
  become: true

- name: Check Filebeat forwarder SSL certificate
  stat: path=/usr/share/logstash/beat-forwarder.crt
  ignore_errors: true
  register: filebeat_forwarder_ssl_exists
  become: true

- name: Create client forwarder SSL certificate
  command: openssl req -subj '/CN={{ ansible_fqdn }}/' -config /etc/pki/tls/openssl_extras.cnf \
    -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout /usr/share/logstash/beat-forwarder.key \
    -out /usr/share/logstash/beat-forwarder.crt
  ignore_errors: true
  when: (filebeat_forwarder_ssl_exists != 0)
  become: true

# We need to insert data to create an initial index, query if it exists
#- name: Check elasticsearch index for content
#  uri:
#    url=http://localhost:9200/_cat/indices
#    method=GET
#    return_content=yes
#  register: elasticsearch_index
#  when: not install_elasticsearch_xpack
#  become: true

# Populate elasticsearch with local syslog data
- name: Populate elasticsearch index with local syslog data
  lineinfile: dest=/etc/rsyslog.conf \
          line="*.* @localhost:{{ logstash_localsyslog_port }}"
  register: rsyslog_updated
  become: true

- name: Restart rsyslogd to populate elasticsearch index
  command: systemctl restart rsyslog.service
  ignore_errors: true
  when: rsyslog_updated != 0
  become: true
